image_finetune: true

output_dir: "ft_vae"
logging_dir: "log"
pretrained_model_path: "pretrained_models/stable-diffusion-v1-5"
pretrained_vae_path: "pretrained_models/sd-vae-ft-mse"


train_data:
  # csv_path:     "./data/UBC_train_info_test.csv"
  csv_path:     "./data/Talk_train_info.csv"
  video_folder: "../Talk_dataset"
  sample_size:  512 # for 40G 256
  sample_stride: 4
  sample_n_frames: 8
  clip_model_path: 'pretrained_models/clip-vit-base-patch32'
  sub_folder: 'deal_chaoming'

# train_data:
#   # csv_path:     "./data/UBC_train_info_test.csv"
#   csv_path:     "./data/TikTok_info.csv"
#   video_folder: "../TikTok_dataset2/TikTok_dataset"
#   sample_size:  512 # for 40G 256
#   sample_stride: 4
#   sample_n_frames: 8
#   clip_model_path: 'pretrained_models/clip-vit-base-patch32'

# train_data:
#   # csv_path:     "./data/UBC_train_info_test.csv"
#   csv_path:     "./data/UBC_train_info.csv"
#   video_folder: "../UBC_dataset"
#   sample_size:  512 # for 40G 256
#   sample_stride: 4
#   sample_n_frames: 8
#   clip_model_path: 'pretrained_models/clip-vit-base-patch32'


trainable_modules:
  # - "motion_modules."
  - "decoder"
  # - "conv_in"

fusion_blocks: "full"


scale_lr: false
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
learning_rate: 5.e-5
train_batch_size: 6
gradient_accumulation_steps: 1
max_grad_norm: 1.0

lr_scheduler: 'constant'
lr_warmup_steps: 0

num_train_epochs:     40000
max_train_steps:      null
checkpointing_steps:  1000

validation_steps:       5000
validation_steps_tuple: [2, 50]

seed: 42
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: False

checkpoints_total_limit: 10
mixed_precision: "fp16"
report_to: "tensorboard"
allow_tf32: true
resume_from_checkpoint: 'latest'
# resume_from_checkpoint: null
dataloader_num_workers: 8